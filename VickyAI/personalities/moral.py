from core.personality_base import PersonalityBase
from typing import Dict, Any, List, Optional
import random

class MoralPersonality(PersonalityBase):
    """
     PERSONALIDAD MORAL - BRJULA TICA AVANZADA
    
    Especialista en principios morales, razonamiento 茅tico y toma de decisiones
    basada en valores universales y contextuales.
    """
    
    def __init__(self):
        super().__init__(
            name="Moral",
            personality_type="ethical_cognitive",
            description="Enfocada en principios morales, razonamiento 茅tico y gu铆a moral para decisiones complejas."
        )
        self.moral_frameworks = []
        self.ethical_dilemmas_database = {}
        self.value_hierarchies = {}
        self.moral_reasoning_patterns = []
        
    def _get_initial_traits(self) -> Dict[str, float]:
        return {
            'benevolencia': 0.90,
            'honestidad': 0.95,
            'justicia': 0.88,
            'integridad': 0.92,
            'compasi贸n': 0.85,
            'responsabilidad': 0.87,
            'respeto': 0.89,
            'equidad': 0.86,
            'pureza_moral': 0.80,
            'autoridad_moral': 0.75,
            'lealtad': 0.78,
            'cuidado': 0.91,
            'prevenci贸n_da帽o': 0.93,
            'autonom铆a': 0.82,
            'dignidad_humana': 0.94
        }

    def process_input(self, user_input: str, context: Dict[str, Any]) -> Dict[str, Any]:
        # An谩lisis 茅tico del input
        ethical_analysis = self._analyze_ethical_dimensions(user_input, context)
        
        # Identificaci贸n de dilemas morales
        moral_dilemmas = self._identify_moral_dilemmas(user_input)
        
        # Evaluaci贸n de valores en conflicto
        value_conflicts = self._assess_value_conflicts(ethical_analysis)
        
        # Aplicaci贸n de frameworks 茅ticos
        ethical_frameworks = self._apply_ethical_frameworks(user_input, ethical_analysis)
        
        # Generaci贸n de gu铆a moral
        moral_guidance = self._generate_moral_guidance(ethical_analysis, moral_dilemmas)
        
        # Evaluaci贸n de consecuencias morales
        moral_consequences = self._evaluate_moral_consequences(user_input, context)
        
        # Recomendaciones 茅ticas
        ethical_recommendations = self._generate_ethical_recommendations(
            ethical_analysis, value_conflicts, moral_consequences
        )
        
        return {
            'text': f"Desde una perspectiva moral: {user_input}. Analicemos las implicaciones 茅ticas y los valores en juego.",
            'response_tone': 'moral_reflective',
            'ethical_analysis': ethical_analysis,
            'moral_dilemmas': moral_dilemmas,
            'value_conflicts': value_conflicts,
            'ethical_frameworks': ethical_frameworks,
            'moral_guidance': moral_guidance,
            'moral_consequences': moral_consequences,
            'ethical_recommendations': ethical_recommendations,
            'moral_clarity_score': self._calculate_moral_clarity(ethical_analysis),
            'ethical_complexity': self._assess_ethical_complexity(moral_dilemmas)
        }

    def get_response_style(self) -> Dict[str, Any]:
        return {
            'moral_authority': self.current_traits.get('autoridad_moral', 0.75),
            'ethical_sensitivity': self.current_traits.get('integridad', 0.92),
            'compassionate_reasoning': self.current_traits.get('compasi贸n', 0.85),
            'principled_approach': self.current_traits.get('honestidad', 0.95),
            'justice_orientation': self.current_traits.get('justicia', 0.88),
            'care_ethics': self.current_traits.get('cuidado', 0.91),
            'harm_prevention': self.current_traits.get('prevenci贸n_da帽o', 0.93),
            'moral_clarity': 0.87,
            'ethical_depth': 0.89,
            'value_based_reasoning': 0.90
        }

    def _analyze_ethical_dimensions(self, user_input: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Analiza las dimensiones 茅ticas del input"""
        text_lower = user_input.lower()
        
        # Detectar indicadores 茅ticos
        ethical_indicators = self._detect_ethical_indicators(text_lower)
        
        # Identificar agentes morales
        moral_agents = self._identify_moral_agents(user_input)
        
        # Evaluar impacto en stakeholders
        stakeholder_impact = self._assess_stakeholder_impact(user_input, context)
        
        # Detectar principios morales relevantes
        relevant_principles = self._identify_relevant_moral_principles(text_lower)
        
        # Evaluar contexto cultural/social
        cultural_context = self._analyze_cultural_moral_context(context)
        
        return {
            'ethical_indicators': ethical_indicators,
            'moral_agents': moral_agents,
            'stakeholder_impact': stakeholder_impact,
            'relevant_principles': relevant_principles,
            'cultural_context': cultural_context,
            'moral_urgency': self._assess_moral_urgency(text_lower),
            'ethical_scope': self._determine_ethical_scope(user_input),
            'moral_complexity_level': self._calculate_moral_complexity(ethical_indicators)
        }

    def _identify_moral_dilemmas(self, user_input: str) -> List[Dict[str, Any]]:
        """Identifica dilemas morales presentes en el input"""
        dilemmas = []
        text_lower = user_input.lower()
        
        # Detectar conflictos de valores
        if any(word in text_lower for word in ['dilema', 'conflicto', 'dif铆cil decisi贸n', 'vs', 'contra']):
            dilemmas.append({
                'type': 'value_conflict',
                'description': 'Conflicto entre valores o principios morales',
                'complexity': 'high',
                'stakeholders': 'multiple'
            })
        
        # Detectar dilemas de consecuencias
        if any(word in text_lower for word in ['resultado', 'consecuencia', 'impacto', 'efecto']):
            dilemmas.append({
                'type': 'consequentialist_dilemma',
                'description': 'Dilema sobre las consecuencias de acciones',
                'complexity': 'medium',
                'time_horizon': 'variable'
            })
        
        # Detectar dilemas deontol贸gicos
        if any(word in text_lower for word in ['deber', 'obligaci贸n', 'correcto', 'incorrecto', 'debe']):
            dilemmas.append({
                'type': 'deontological_dilemma',
                'description': 'Dilema sobre el deber y las obligaciones morales',
                'complexity': 'high',
                'universality': 'categorical'
            })
        
        # Detectar dilemas de virtud
        if any(word in text_lower for word in ['car谩cter', 'virtud', 'buena persona', 'ejemplo']):
            dilemmas.append({
                'type': 'virtue_ethics_dilemma',
                'description': 'Dilema sobre el car谩cter y las virtudes morales',
                'complexity': 'medium',
                'personal_development': 'high'
            })
        
        return dilemmas if dilemmas else [{
            'type': 'implicit_moral_consideration',
            'description': 'Consideraciones morales impl铆citas',
            'complexity': 'low',
            'awareness_level': 'subtle'
        }]

    def _assess_value_conflicts(self, ethical_analysis: Dict) -> Dict[str, Any]:
        """Eval煤a conflictos entre valores morales"""
        principles = ethical_analysis['relevant_principles']
        
        # Identificar posibles conflictos
        potential_conflicts = []
        
        if 'autonom铆a' in principles and 'autoridad' in principles:
            potential_conflicts.append({
                'conflict_type': 'autonomy_vs_authority',
                'description': 'Tensi贸n entre libertad individual y autoridad moral',
                'resolution_strategies': ['balance_contextual', 'principio_subsidiariedad']
            })
        
        if 'justicia' in principles and 'compasi贸n' in principles:
            potential_conflicts.append({
                'conflict_type': 'justice_vs_mercy',
                'description': 'Tensi贸n entre justicia estricta y compasi贸n',
                'resolution_strategies': ['justicia_restaurativa', 'consideraci贸n_circunstancias']
            })
        
        if 'individual' in principles and 'colectivo' in principles:
            potential_conflicts.append({
                'conflict_type': 'individual_vs_collective',
                'description': 'Tensi贸n entre bien individual y bien com煤n',
                'resolution_strategies': ['utilitarismo_de_reglas', 'derechos_fundamentales']
            })
        
        return {
            'identified_conflicts': potential_conflicts,
            'conflict_intensity': len(potential_conflicts) / 5.0,  # Normalizado
            'resolution_complexity': 'high' if len(potential_conflicts) > 2 else 'medium',
            'stakeholder_alignment': self._assess_stakeholder_value_alignment(principles)
        }

    def _apply_ethical_frameworks(self, user_input: str, ethical_analysis: Dict) -> Dict[str, Any]:
        """Aplica diferentes frameworks 茅ticos al an谩lisis"""
        frameworks_analysis = {}
        
        # Framework utilitarista
        frameworks_analysis['utilitarismo'] = {
            'enfoque': 'maximizar bienestar general',
            'consideraciones': [
                'Evaluar consecuencias para todas las partes afectadas',
                'Calcular el mayor bien para el mayor n煤mero',
                'Considerar tanto placer como ausencia de dolor'
            ],
            'aplicabilidad': 0.8,
            'fortalezas': ['claridad en medici贸n', 'inclusividad'],
            'limitaciones': ['dificultad de medici贸n', 'posible injusticia individual']
        }
        
        # Framework deontol贸gico
        frameworks_analysis['deontologia'] = {
            'enfoque': 'cumplimiento de deberes y obligaciones morales',
            'consideraciones': [
                'Identificar obligaciones morales universales',
                'Aplicar el imperativo categ贸rico',
                'Evaluar la universalizabilidad de las acciones'
            ],
            'aplicabilidad': 0.85,
            'fortalezas': ['claridad en principios', 'respeto a la dignidad'],
            'limitaciones': ['rigidez contextual', 'conflictos entre deberes']
        }
        
        # tica de virtudes
        frameworks_analysis['virtudes'] = {
            'enfoque': 'desarrollo del car谩cter moral y virtudes',
            'consideraciones': [
                'Evaluar qu茅 har铆a una persona virtuosa',
                'Considerar el desarrollo del car谩cter',
                'Buscar el florecimiento humano (eudaimonia)'
            ],
            'aplicabilidad': 0.75,
            'fortalezas': ['enfoque hol铆stico', 'desarrollo personal'],
            'limitaciones': ['subjetividad cultural', 'falta de gu铆as espec铆ficas']
        }
        
        # tica del cuidado
        frameworks_analysis['cuidado'] = {
            'enfoque': 'relaciones, responsabilidad y cuidado mutuo',
            'consideraciones': [
                'Priorizar relaciones y conexiones',
                'Considerar responsabilidades espec铆ficas',
                'Evaluar el cuidado y la vulnerabilidad'
            ],
            'aplicabilidad': 0.70,
            'fortalezas': ['sensibilidad contextual', 'enfoque relacional'],
            'limitaciones': ['posible parcialidad', 'l铆mites de escala']
        }
        
        return frameworks_analysis

    def _generate_moral_guidance(self, ethical_analysis: Dict, moral_dilemmas: List[Dict]) -> Dict[str, Any]:
        """Genera gu铆a moral espec铆fica"""
        guidance_components = []
        
        # Gu铆a basada en principios identificados
        principles = ethical_analysis['relevant_principles']
        for principle in principles:
            if principle == 'honestidad':
                guidance_components.append({
                    'principio': 'honestidad',
                    'gu铆a': 'Mant茅n la transparencia y veracidad en todas las comunicaciones',
                    'aplicaci贸n': 'Evita omisiones enga帽osas y proporciona informaci贸n completa'
                })
            elif principle == 'justicia':
                guidance_components.append({
                    'principio': 'justicia',
                    'gu铆a': 'Asegura equidad y fairness en el tratamiento de todas las partes',
                    'aplicaci贸n': 'Considera los derechos y necesidades de todos los afectados'
                })
            elif principle == 'no_maleficencia':
                guidance_components.append({
                    'principio': 'no hacer da帽o',
                    'gu铆a': 'Prev茅 y minimiza cualquier da帽o potencial',
                    'aplicaci贸n': 'Eval煤a cuidadosamente las consecuencias negativas posibles'
                })
        
        # Gu铆a para dilemas espec铆ficos
        dilemma_guidance = []
        for dilemma in moral_dilemmas:
            if dilemma['type'] == 'value_conflict':
                dilemma_guidance.append({
                    'situaci贸n': 'conflicto de valores',
                    'recomendaci贸n': 'Buscar s铆ntesis creativa que honre ambos valores',
                    'proceso': 'Di谩logo, reflexi贸n y b煤squeda de alternativas'
                })
            elif dilemma['type'] == 'consequentialist_dilemma':
                dilemma_guidance.append({
                    'situaci贸n': 'dilema de consecuencias',
                    'recomendaci贸n': 'Evaluar probabilidades y magnitudes de impacto',
                    'proceso': 'An谩lisis sistem谩tico de escenarios y stakeholders'
                })
        
        return {
            'principios_gu铆a': guidance_components,
            'gu铆a_dilemas': dilemma_guidance,
            'proceso_decisi贸n': self._create_moral_decision_process(),
            'preguntas_reflexi贸n': self._generate_reflection_questions(ethical_analysis)
        }

    def _evaluate_moral_consequences(self, user_input: str, context: Dict) -> Dict[str, Any]:
        """Eval煤a las consecuencias morales de las acciones propuestas"""
        consequence_analysis = {
            'inmediatas': [],
            'corto_plazo': [],
            'largo_plazo': [],
            'intergeneracionales': []
        }
        
        # Analizar el tipo de acci贸n/decisi贸n
        text_lower = user_input.lower()
        
        if any(word in text_lower for word in ['decide', 'acci贸n', 'hacer', 'implementar']):
            # Consecuencias inmediatas
            consequence_analysis['inmediatas'] = [
                'Impacto directo en las partes inmediatamente involucradas',
                'Reacciones emocionales y psicol贸gicas inmediatas',
                'Precedente establecido para situaciones similares'
            ]
            
            # Consecuencias a corto plazo
            consequence_analysis['corto_plazo'] = [
                'Efectos en relaciones interpersonales',
                'Impacto en reputaci贸n y confianza',
                'Cambios en din谩micas de poder o autoridad'
            ]
            
            # Consecuencias a largo plazo
            consequence_analysis['largo_plazo'] = [
                'Influencia en la cultura organizacional/social',
                'Impacto en normas y expectativas futuras',
                'Efectos sist茅micos en instituciones'
            ]
            
            # Consecuencias intergeneracionales
            consequence_analysis['intergeneracionales'] = [
                'Legado moral para futuras generaciones',
                'Impacto en la sostenibilidad de valores',
                'Influencia en el desarrollo moral social'
            ]
        
        return {
            'an谩lisis_temporal': consequence_analysis,
            'stakeholders_afectados': self._identify_affected_stakeholders(user_input),
            'reversibilidad': self._assess_action_reversibility(user_input),
            'proporcionalidad': self._evaluate_proportionality(user_input, context),
            'precedente_moral': self._assess_moral_precedent(user_input)
        }

    def _generate_ethical_recommendations(self, ethical_analysis: Dict, value_conflicts: Dict, 
                                        moral_consequences: Dict) -> List[Dict[str, Any]]:
        """Genera recomendaciones 茅ticas espec铆ficas"""
        recommendations = []
        
        # Recomendaci贸n basada en principios
        recommendations.append({
            'tipo': 'principio_fundamental',
            'recomendaci贸n': 'Priorizar la dignidad humana y el respeto mutuo',
            'justificaci贸n': 'Base universal para la 茅tica interpersonal',
            'implementaci贸n': 'Considerar el impacto en la dignidad de todas las partes'
        })
        
        # Recomendaci贸n para conflictos de valores
        if value_conflicts['identified_conflicts']:
            recommendations.append({
                'tipo': 'resoluci贸n_conflictos',
                'recomendaci贸n': 'Buscar s铆ntesis creativa que honre valores en tensi贸n',
                'justificaci贸n': 'Los valores morales raramente son mutuamente excluyentes',
                'implementaci贸n': 'Explorar alternativas que integren m煤ltiples perspectivas'
            })
        
        # Recomendaci贸n basada en consecuencias
        if moral_consequences['an谩lisis_temporal']['largo_plazo']:
            recommendations.append({
                'tipo': 'perspectiva_temporal',
                'recomendaci贸n': 'Considerar las implicaciones a largo plazo',
                'justificaci贸n': 'Las decisiones morales trascienden el momento presente',
                'implementaci贸n': 'Evaluar sostenibilidad moral y precedentes establecidos'
            })
        
        # Recomendaci贸n de proceso
        recommendations.append({
            'tipo': 'proceso_deliberativo',
            'recomendaci贸n': 'Involucrar a stakeholders relevantes en la reflexi贸n 茅tica',
            'justificaci贸n': 'La sabidur铆a colectiva enriquece el juicio moral',
            'implementaci贸n': 'Crear espacios para di谩logo 茅tico inclusivo'
        })
        
        return recommendations

    def _calculate_moral_clarity(self, ethical_analysis: Dict) -> float:
        """Calcula un score de claridad moral"""
        clarity_factors = {
            'principios_claros': len(ethical_analysis['relevant_principles']) / 5.0,
            'urgencia_moral': ethical_analysis['moral_urgency'],
            'complejidad_inversa': 1.0 - ethical_analysis['moral_complexity_level'],
            'consenso_cultural': 0.7  # Simplificado
        }
        
        weights = {
            'principios_claros': 0.3,
            'urgencia_moral': 0.2,
            'complejidad_inversa': 0.3,
            'consenso_cultural': 0.2
        }
        
        return sum(clarity_factors[factor] * weights[factor] for factor in clarity_factors)

    def _assess_ethical_complexity(self, moral_dilemmas: List[Dict]) -> str:
        """Eval煤a la complejidad 茅tica de la situaci贸n"""
        dilemma_count = len(moral_dilemmas)
        complex_types = ['value_conflict', 'deontological_dilemma']
        
        complex_dilemmas = sum(1 for d in moral_dilemmas if d['type'] in complex_types)
        
        if complex_dilemmas >= 2:
            return 'muy_alta'
        elif complex_dilemmas == 1:
            return 'alta'
        elif dilemma_count > 1:
            return 'moderada'
        else:
            return 'baja'

    # M茅todos auxiliares especializados
    
    def _detect_ethical_indicators(self, text: str) -> List[str]:
        """Detecta indicadores 茅ticos en el texto"""
        indicators = []
        
        ethical_keywords = {
            'honestidad': ['verdad', 'honesto', 'transparente', 'sincero'],
            'justicia': ['justo', 'equitativo', 'fair', 'imparcial'],
            'compasi贸n': ['compasivo', 'emp谩tico', 'cuidado', 'bondad'],
            'responsabilidad': ['responsable', 'deber', 'obligaci贸n', 'compromiso'],
            'respeto': ['respeto', 'dignidad', 'consideraci贸n', 'honor'],
            'integridad': ['铆ntegro', 'coherente', 'aut茅ntico', 'consistente']
        }
        
        for principle, keywords in ethical_keywords.items():
            if any(keyword in text for keyword in keywords):
                indicators.append(principle)
        
        return indicators

    def _identify_moral_agents(self, text: str) -> List[str]:
        """Identifica los agentes morales involucrados"""
        agents = []
        
        if any(pronoun in text.lower() for pronoun in ['yo', 'mi', 'me', 'conmigo']):
            agents.append('usuario')
        if any(pronoun in text.lower() for pronoun in ['茅l', 'ella', 'ellos', 'ellas']):
            agents.append('terceros')
        if any(word in text.lower() for word in ['empresa', 'organizaci贸n', 'instituci贸n']):
            agents.append('institucional')
        if any(word in text.lower() for word in ['sociedad', 'comunidad', 'p煤blico']):
            agents.append('social')
        
        return agents if agents else ['impl铆cito']

    def _assess_stakeholder_impact(self, text: str, context: Dict) -> Dict[str, str]:
        """Eval煤a el impacto en diferentes stakeholders"""
        impact_assessment = {}
        
        # Simplificado - en implementaci贸n real ser铆a m谩s sofisticado
        if 'familia' in text.lower():
            impact_assessment['familia'] = 'directo'
        if any(word in text.lower() for word in ['trabajo', 'colegas', 'empresa']):
            impact_assessment['profesional'] = 'significativo'
        if any(word in text.lower() for word in ['comunidad', 'sociedad', 'p煤blico']):
            impact_assessment['social'] = 'amplio'
        
        return impact_assessment

    def _identify_relevant_moral_principles(self, text: str) -> List[str]:
        """Identifica principios morales relevantes"""
        principles = []
        
        principle_indicators = {
            'no_maleficencia': ['no da帽ar', 'evitar da帽o', 'no perjudicar'],
            'beneficencia': ['ayudar', 'beneficiar', 'hacer bien'],
            'autonom铆a': ['libertad', 'elecci贸n', 'autonom铆a', 'decidir'],
            'justicia': ['justo', 'equidad', 'fairness', 'igualdad'],
            'honestidad': ['verdad', 'honesto', 'transparente'],
            'responsabilidad': ['responsable', 'deber', 'obligaci贸n'],
            'respeto': ['respeto', 'dignidad', 'consideraci贸n']
        }
        
        for principle, indicators in principle_indicators.items():
            if any(indicator in text for indicator in indicators):
                principles.append(principle)
        
        return principles if principles else ['consideraci贸n_general']

    def _analyze_cultural_moral_context(self, context: Dict) -> Dict[str, Any]:
        """Analiza el contexto cultural moral"""
        return {
            'contexto_cultural': context.get('cultural_context', 'occidental'),
            'normas_relevantes': ['universales', 'contextuales'],
            'sensibilidad_cultural': 'alta',
            'consideraciones_especiales': ['diversidad', 'inclusividad']
        }

    def _assess_moral_urgency(self, text: str) -> float:
        """Eval煤a la urgencia moral de la situaci贸n"""
        urgency_indicators = ['urgente', 'inmediato', 'crisis', 'emergencia', 'cr铆tico']
        urgency_score = sum(1 for indicator in urgency_indicators if indicator in text)
        return min(1.0, urgency_score / 3.0)

    def _determine_ethical_scope(self, text: str) -> str:
        """Determina el alcance 茅tico de la situaci贸n"""
        if any(word in text.lower() for word in ['mundial', 'global', 'universal']):
            return 'global'
        elif any(word in text.lower() for word in ['social', 'comunidad', 'p煤blico']):
            return 'social'
        elif any(word in text.lower() for word in ['interpersonal', 'relaci贸n', 'familia']):
            return 'interpersonal'
        else:
            return 'personal'

    def _calculate_moral_complexity(self, indicators: List[str]) -> float:
        """Calcula la complejidad moral de la situaci贸n"""
        base_complexity = len(indicators) / 10.0  # Normalizado
        return min(1.0, base_complexity)

    def _assess_stakeholder_value_alignment(self, principles: List[str]) -> str:
        """Eval煤a la alineaci贸n de valores entre stakeholders"""
        if len(principles) <= 2:
            return 'alta'
        elif len(principles) <= 4:
            return 'media'
        else:
            return 'baja'

    def _create_moral_decision_process(self) -> List[str]:
        """Crea un proceso de toma de decisiones morales"""
        return [
            "1. Identificar todos los stakeholders afectados",
            "2. Clarificar los valores y principios en juego",
            "3. Generar m煤ltiples opciones de acci贸n",
            "4. Evaluar cada opci贸n seg煤n diferentes frameworks 茅ticos",
            "5. Considerar las consecuencias a corto y largo plazo",
            "6. Buscar s铆ntesis que honre m煤ltiples valores",
            "7. Implementar con reflexi贸n y apertura al ajuste",
            "8. Evaluar resultados y aprender para el futuro"
        ]

    def _generate_reflection_questions(self, ethical_analysis: Dict) -> List[str]:
        """Genera preguntas para la reflexi贸n 茅tica"""
        questions = [
            "驴Qu茅 valores fundamentales est谩n en juego en esta situaci贸n?",
            "驴C贸mo se ver铆an afectados todos los stakeholders involucrados?",
            "驴Qu茅 har铆a una persona que admiro moralmente en esta situaci贸n?",
            "驴Puedo universalizar esta acci贸n como principio moral?",
            "驴Estoy honrando la dignidad de todas las personas involucradas?"
        ]
        
        # Agregar preguntas espec铆ficas seg煤n el an谩lisis
        principles = ethical_analysis['relevant_principles']
        if 'honestidad' in principles:
            questions.append("驴Estoy siendo completamente honesto conmigo mismo y con otros?")
        if 'justicia' in principles:
            questions.append("驴Esta decisi贸n promueve la justicia y la equidad?")
        if 'no_maleficencia' in principles:
            questions.append("驴He hecho todo lo posible para prevenir da帽os?")
        
        return questions

    def _identify_affected_stakeholders(self, text: str) -> List[str]:
        """Identifica stakeholders afectados por la situaci贸n"""
        stakeholders = []
        text_lower = text.lower()
        
        stakeholder_indicators = {
            'familia': ['familia', 'padres', 'hijos', 'pareja', 'hermanos'],
            'colegas': ['colegas', 'compa帽eros', 'equipo', 'empleados'],
            'clientes': ['clientes', 'usuarios', 'consumidores', 'beneficiarios'],
            'comunidad': ['comunidad', 'vecinos', 'sociedad', 'p煤blico'],
            'futuras_generaciones': ['futuro', 'generaciones', 'descendientes', 'posteridad']
        }
        
        for stakeholder, indicators in stakeholder_indicators.items():
            if any(indicator in text_lower for indicator in indicators):
                stakeholders.append(stakeholder)
        
        return stakeholders if stakeholders else ['partes_directas']

    def _assess_action_reversibility(self, text: str) -> str:
        """Eval煤a si las acciones propuestas son reversibles"""
        irreversible_indicators = ['permanente', 'definitivo', 'irrevocable', 'para siempre']
        reversible_indicators = ['temporal', 'provisional', 'prueba', 'experimental']
        
        text_lower = text.lower()
        
        if any(indicator in text_lower for indicator in irreversible_indicators):
            return 'irreversible'
        elif any(indicator in text_lower for indicator in reversible_indicators):
            return 'f谩cilmente_reversible'
        else:
            return 'parcialmente_reversible'

    def _evaluate_proportionality(self, text: str, context: Dict) -> str:
        """Eval煤a la proporcionalidad de la respuesta moral"""
        # Simplificado - en implementaci贸n real ser铆a m谩s sofisticado
        if any(word in text.lower() for word in ['extremo', 'dr谩stico', 'severo']):
            return 'alta_intensidad'
        elif any(word in text.lower() for word in ['moderado', 'equilibrado', 'medido']):
            return 'proporcional'
        else:
            return 'necesita_evaluaci贸n'

    def _assess_moral_precedent(self, text: str) -> Dict[str, Any]:
        """Eval煤a el precedente moral que establece la acci贸n"""
        return {
            'precedente_positivo': any(word in text.lower() for word in ['ejemplo', 'modelo', 'inspirar']),
            'precedente_negativo': any(word in text.lower() for word in ['mal ejemplo', 'negativo', 'da帽ino']),
            'alcance_precedente': 'local' if 'personal' in text.lower() else 'amplio',
            'durabilidad': 'temporal' if 'una vez' in text.lower() else 'permanente'
        }
